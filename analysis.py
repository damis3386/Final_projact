#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø£Ø¯Ø§Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø±Ù‚Ù…ÙŠ - Digital Forensics Tool
Ø¥ØµØ¯Ø§Ø±: 2.0
Ø§Ù„Ù…Ø·ÙˆØ±: Ù‡ÙŠÙ„Ø© Ùˆ Ù„ÙŠÙ†
"""

import os
import re
import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional

# --------------------------
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù„Ø§Ø²Ù…Ø©
# --------------------------
os.makedirs("results", exist_ok=True)
os.makedirs("logs", exist_ok=True)
os.makedirs("data", exist_ok=True)   # Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# --------------------------

# ==========================
# ğŸ”§ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Logging)
# ==========================
LOG_PATH = os.path.join("logs", "forensics.log")
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_PATH, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==========================
# ğŸ¯ Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# ==========================
class Config:
    """Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"""
    SUPPORTED_EXTENSIONS = {'.log', '.txt', '.csv', '.json', '.zip'}
    MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
    RISK_THRESHOLDS = {
        'HIGH': 20,
        'MEDIUM': 10,
        'LOW': 0
    }

# ==========================
# ğŸŸ¢ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯
# ==========================
class RuleManager:
    """Ù…Ø¯ÙŠØ± Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
    def __init__(self, rules_file: str = 'rules.json'):
        self.rules_file = rules_file
        self.rules = self._load_rules()

    def _load_rules(self) -> Dict[str, List[Dict[str, Any]]]:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù† Ù…Ù„Ù JSON Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©"""
        try:
            if os.path.exists(self.rules_file):
                with open(self.rules_file, 'r', encoding='utf-8') as f:
                    rules = json.load(f)
                count = sum(len(v) for v in rules.values()) if isinstance(rules, dict) else 0
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {count} Ù‚Ø§Ø¹Ø¯Ø© Ù…Ù† {self.rules_file}")
                return rules
            else:
                logger.warning(f"âš ï¸  Ù…Ù„Ù Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ {self.rules_file} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©")
                return self._get_default_rules()
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ù…Ù„Ù Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯: {e}")
            return self._get_default_rules()
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯: {e}")
            return self._get_default_rules()

    def _get_default_rules(self) -> Dict[str, List[Dict[str, Any]]]:
        """Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© (Ù…ÙˆØ³Ø¹Ø©)"""
        return {
            "high_risk_patterns": [
                {"name": "Ransomware", "pattern": r"\bransomware\b", "description": "Ø¨Ø±Ù…Ø¬ÙŠØ© ÙØ¯ÙŠØ©", "score": 10, "category": "Ø¨Ø±Ø§Ù…Ø¬ Ø¶Ø§Ø±Ø©"},
                {"name": "SQL Injection", "pattern": r"sql\s+injection|\binjection\b", "description": "Ù…Ø­Ø§ÙˆÙ„Ø© Ø­Ù‚Ù† SQL", "score": 10, "category": "Ù‡Ø¬ÙˆÙ… ØªØ·Ø¨ÙŠÙ‚ÙŠ"},
                {"name": "Privilege Escalation", "pattern": r"privilege\s+escalation", "description": "Ù…Ø­Ø§ÙˆÙ„Ø© ØªØµØ¹ÙŠØ¯ ØµÙ„Ø§Ø­ÙŠØ§Øª", "score": 8, "category": "Ù‡Ø¬ÙˆÙ… ØªØ·Ø¨ÙŠÙ‚ÙŠ"}
            ],
            "medium_risk_patterns": [
                {"name": "Malware", "pattern": r"\bmalware\b|\bvirus\b|\btrojan\b", "description": "Ø¨Ø±Ø§Ù…Ø¬ Ø¶Ø§Ø±Ø©", "score": 5, "category": "Ø¨Ø±Ø§Ù…Ø¬ Ø¶Ø§Ø±Ø©"},
                {"name": "Unauthorized Access", "pattern": r"\bunauthorized\b|\bunauthorized\s+access\b", "description": "ÙˆØµÙˆÙ„ ØºÙŠØ± Ù…ØµØ±Ø­ Ø¨Ù‡", "score": 5, "category": "Ø£Ù…Ù† Ø§Ù„Ø´Ø¨ÙƒØ§Øª"},
                {"name": "Failed Login", "pattern": r"\bfailed\s+login\b|\blogin\s+failed\b|\bauthentication\s+failed\b", "description": "Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø¯Ø®ÙˆÙ„ ÙØ§Ø´Ù„Ø©", "score": 5, "category": "Ø£Ù…Ø§Ù† Ø§Ù„Ù†Ø¸Ø§Ù…"},
                {"name": "Brute Force Pattern", "pattern": r"(failed\s+login.*){3,}", "description": "Ù†Ù…Ø· ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ù‡Ø¬ÙˆÙ… ØªØ®Ù…ÙŠÙ† Ù…ØªÙƒØ±Ø±", "score": 6, "category": "Ù‡Ø¬ÙˆÙ… Ø´Ø¨ÙƒÙŠ"}
            ],
            "low_risk_patterns": [
                {"name": "Warning", "pattern": r"\bwarning\b", "description": "ØªØ­Ø°ÙŠØ± Ù†Ø¸Ø§Ù…", "score": 1, "category": "Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"},
                {"name": "Timeout", "pattern": r"\btimeout\b|\btime\s?out\b", "description": "Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù‡Ù„Ø© Ø§ØªØµØ§Ù„", "score": 1, "category": "Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…"},
                {"name": "Scan", "pattern": r"\bscan\b|\bscanning\b", "description": "Ù†Ø´Ø§Ø· ÙØ­Øµ/Ù…Ø³Ø­", "score": 1, "category": "Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø´Ø¨ÙƒØ©"}
            ]
        }

    def get_all_rules(self) -> Dict[str, List[Dict[str, Any]]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯"""
        return self.rules

# ==========================
# ğŸŸ¢ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù„ÙØ§Øª
# ==========================
import io
import zipfile
import csv

class FileManager:
    """Ù…Ø¯ÙŠØ± Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ù„ÙØ§Øª â€” ÙŠØ¯Ø¹Ù… txt/csv/json/zip (Ù…Ø­ØªÙˆÙ‰ Ù†ØµÙŠ)"""
    @staticmethod
    def read_file(file_path: str, encoding: str = 'utf-8') -> Dict[str, Optional[object]]:
        """
        ÙŠÙØ±Ø¬Ø¹ dict:
        { "text": str|None, "meta": {...}, "error": None|str }
        """
        try:
            if not os.path.exists(file_path):
                return {"text": None, "meta": None, "error": f"Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {file_path}"}
            size = os.path.getsize(file_path)
            if size > Config.MAX_FILE_SIZE:
                return {"text": None, "meta": None, "error": f"Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹: {size} Ø¨Ø§ÙŠØª"}
            name = os.path.basename(file_path)
            _, ext = os.path.splitext(name.lower())
            meta = {"path": file_path, "size": size, "ext": ext, "files_in_archive": None}

            if ext in ('.txt', '.log'):
                with open(file_path, 'r', encoding=encoding, errors='replace') as f:
                    text = f.read()
                logger.info(f"ğŸ“– ØªÙ… Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {file_path} ({size} Ø¨Ø§ÙŠØªØŒ {len(text.splitlines())} Ø³Ø·Ø±)")
                return {"text": text, "meta": meta, "error": None}

            if ext == '.csv':
                rows = []
                with open(file_path, 'r', encoding=encoding, errors='replace', newline='') as f:
                    reader = csv.DictReader(f)
                    for r in reader:
                        rows.append(json.dumps(r, ensure_ascii=False))
                text = "\n".join(rows)
                return {"text": text, "meta": meta, "error": None}

            if ext == '.json':
                with open(file_path, 'r', encoding=encoding, errors='replace') as f:
                    data = json.load(f)
                if isinstance(data, list):
                    text = "\n".join(json.dumps(it, ensure_ascii=False) for it in data)
                else:
                    text = json.dumps(data, ensure_ascii=False)
                return {"text": text, "meta": meta, "error": None}

            if ext == '.zip':
                contents = []
                names = []
                with zipfile.ZipFile(file_path, 'r') as z:
                    for info in z.infolist():
                        names.append(info.filename)
                        _, e = os.path.splitext(info.filename.lower())
                        if e in ('.txt', '.log'):
                            try:
                                with z.open(info) as f:
                                    data = f.read().decode(encoding, errors='replace')
                                contents.append(f"--- FILE: {info.filename} ---\n{data}")
                            except Exception:
                                contents.append(f"--- FILE: {info.filename} (unreadable) ---")
                        elif e == '.csv':
                            try:
                                with z.open(info) as f:
                                    text = f.read().decode(encoding, errors='replace')
                                reader = csv.DictReader(io.StringIO(text))
                                rows = [json.dumps(r, ensure_ascii=False) for r in reader]
                                contents.append("\n".join(rows))
                            except Exception:
                                contents.append(f"--- FILE: {info.filename} (csv parse error) ---")
                        elif e == '.json':
                            try:
                                with z.open(info) as f:
                                    text = f.read().decode(encoding, errors='replace')
                                    data = json.loads(text)
                                if isinstance(data, list):
                                    contents.append("\n".join(json.dumps(it, ensure_ascii=False) for it in data))
                                else:
                                    contents.append(json.dumps(data, ensure_ascii=False))
                            except Exception:
                                contents.append(f"--- FILE: {info.filename} (json parse error) ---")
                        else:
                            contents.append(f"--- FILE: {info.filename} (skipped - unsupported) ---")
                meta["files_in_archive"] = names
                return {"text": "\n\n".join(contents), "meta": meta, "error": None}

            return {"text": None, "meta": meta, "error": f"Unsupported extension: {ext}"}

        except UnicodeDecodeError:
            try:
                with open(file_path, 'r', encoding='latin-1') as f:
                    text = f.read()
                return {"text": text, "meta": meta, "error": None}
            except Exception as e:
                return {"text": None, "meta": None, "error": str(e)}
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
            return {"text": None, "meta": None, "error": str(e)}

# ==========================
# ğŸŸ¢ Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ==========================
class ForensicAnalyzer:
    """Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø¬Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    def __init__(self, rules_file: str = 'rules.json'):
        self.rule_manager = RuleManager(rules_file=rules_file)
        self.file_manager = FileManager()

    def analyze_log_basic(self, content: str) -> Dict[str, Any]:
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ø³Ø¬Ù„Ø§Øª"""
        lines = content.splitlines()
        error_lines = [line for line in lines if re.search(r'\berror\b', line, re.IGNORECASE)]
        warning_lines = [line for line in lines if re.search(r'\bwarning\b', line, re.IGNORECASE)]
        info_lines = [line for line in lines if re.search(r'\binfo\b', line, re.IGNORECASE)]
        return {
            "total_lines": len(lines),
            "errors": len(error_lines),
            "warnings": len(warning_lines),
            "info_events": len(info_lines),
            "analysis_timestamp": datetime.now().isoformat()
        }

    def search_suspicious_patterns(self, content: str) -> List[Dict[str, Any]]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯"""
        rules = self.rule_manager.get_all_rules()
        found_items: List[Dict[str, Any]] = []
        risk_levels_mapping = {
            "high_risk_patterns": {"icon": "ğŸŸ¥", "level": "Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø®Ø·ÙˆØ±Ø©"},
            "medium_risk_patterns": {"icon": "ğŸŸ¨", "level": "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·ÙˆØ±Ø©"},
            "low_risk_patterns": {"icon": "ğŸŸ©", "level": "Ù…Ù†Ø®ÙØ¶ Ø§Ù„Ø®Ø·ÙˆØ±Ø©"}
        }

        for rule_category, risk_info in risk_levels_mapping.items():
            for rule in rules.get(rule_category, []):
                try:
                    matches = re.findall(rule['pattern'], content, flags=re.IGNORECASE)
                except re.error as e:
                    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ù…Ø· {rule.get('pattern')}: {e}")
                    matches = []
                if matches:
                    examples = []
                    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù€ matches Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† tuples Ø£Ùˆ Ù‚ÙˆØ§Ø¦Ù… Ø¨Ø³Ø¨Ø¨ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„ØªÙ‚Ø§Ø· ÙÙŠ Ø§Ù„ regex
                    for m in matches[:3]:
                        if isinstance(m, (list, tuple)):
                            examples.append(" ".join([str(x) for x in m if x]))
                        else:
                            examples.append(str(m))
                    found_items.append({
                        "risk_icon": risk_info["icon"],
                        "risk_level": risk_info["level"],
                        "name": rule.get('name'),
                        "pattern": rule.get('pattern'),
                        "count": len(matches),
                        "score": rule.get('score', 1),
                        "description": rule.get('description', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙˆØµÙ'),
                        "category": rule.get('category', 'ØºÙŠØ± Ù…ØµÙ†Ù'),
                        "examples": examples,
                        "first_occurrence": examples[0] if examples else ""
                    })
                    logger.info(f"ğŸ” Ø¹ÙØ«Ø± Ø¹Ù„Ù‰: {rule.get('name')} ({len(matches)} Ù…Ø±Ø©)")
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· (score * count) ØªÙ†Ø§Ø²Ù„ÙŠØ§Ù‹
        found_items.sort(key=lambda x: x['score'] * x['count'], reverse=True)
        return found_items

    def advanced_statistical_analysis(self, content: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠ Ù…ØªÙ‚Ø¯Ù…"""
        lines = content.splitlines()
        # Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªÙˆÙ‚ÙŠØª ÙˆØ§Ù„ØªÙˆØ§Ø±ÙŠØ® ÙˆØ¹Ù†Ø§ÙˆÙŠÙ† IP Ùˆ URLs
        times = re.findall(r'(\d{1,2}:\d{2}:\d{2})', content)
        dates = re.findall(r'(\d{4}-\d{2}-\d{2}|\d{2}/\d{2}/\d{4})', content)
        ips = re.findall(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', content)
        urls = re.findall(r'https?://[^\s]+', content)
        suspicious_patterns = self.search_suspicious_patterns(content)
        total_risk_score = sum(item['score'] * item['count'] for item in suspicious_patterns)

        if total_risk_score >= Config.RISK_THRESHOLDS['HIGH']:
            overall_risk = "ğŸŸ¥ Ø¹Ø§Ù„ÙŠ"
            action_required = "Ù†Ø¹Ù… - ØªØ¯Ø®Ù„ ÙÙˆØ±ÙŠ Ù…Ø·Ù„ÙˆØ¨"
        elif total_risk_score >= Config.RISK_THRESHOLDS['MEDIUM']:
            overall_risk = "ğŸŸ¨ Ù…ØªÙˆØ³Ø·"
            action_required = "Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…Ø³ØªÙ…Ø±Ø©"
        else:
            overall_risk = "ğŸŸ© Ù…Ù†Ø®ÙØ¶"
            action_required = "Ù„Ø§ - Ø¶Ù…Ù† Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ"

        return {
            "Ø§Ù„ØªØ­Ù„ÙŠÙ„_Ø§Ù„Ø²Ù…Ù†ÙŠ": {
                "Ø£ÙˆÙ„_Ø­Ø¯Ø«": times[0] if times else "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ",
                "Ø¢Ø®Ø±_Ø­Ø¯Ø«": times[-1] if times else "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ",
                "Ø§Ù„ÙØªØ±Ø©_Ø§Ù„Ø²Ù…Ù†ÙŠØ©": f"{times[0]} - {times[-1]}" if times else "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ",
                "Ø¹Ø¯Ø¯_Ø§Ù„Ø£ÙˆÙ‚Ø§Øª_Ø§Ù„Ù…Ø³Ø¬Ù„Ø©": len(times)
            },
            "Ø§Ù„ØªØ­Ù„ÙŠÙ„_Ø§Ù„Ø´Ø¨ÙƒÙŠ": {
                "Ø¹Ù†Ø§ÙˆÙŠÙ†_IP_Ù…Ø®ØªÙ„ÙØ©": len(set(ips)),
                "Ø¥Ø¬Ù…Ø§Ù„ÙŠ_Ø¹Ù†Ø§ÙˆÙŠÙ†_IP": len(ips),
                "Ø¹Ù†Ø§ÙˆÙŠÙ†_URL_Ù…ÙƒØªØ´ÙØ©": len(urls)
            },
            "ØªÙ‚ÙŠÙŠÙ…_Ø§Ù„Ø®Ø·ÙˆØ±Ø©": {
                "Ù†Ù‚Ø§Ø·_Ø§Ù„Ø®Ø·ÙˆØ±Ø©_Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©": total_risk_score,
                "Ù…Ø³ØªÙˆÙ‰_Ø§Ù„Ø®Ø·ÙˆØ±Ø©_Ø§Ù„Ø´Ø§Ù…Ù„": overall_risk,
                "ÙŠØªØ·Ù„Ø¨_ØªØ¯Ø®Ù„": action_required,
                "Ø¹Ø¯Ø¯_Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯Ø§Øª_Ø§Ù„Ù…ÙƒØªØ´ÙØ©": len(suspicious_patterns)
            },
            "Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª_Ø§Ù„Ø¹Ø§Ù…Ø©": {
                "Ø¥Ø¬Ù…Ø§Ù„ÙŠ_Ø§Ù„Ø£Ø­Ø¯Ø§Ø«": len(lines),
                "Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®_Ø§Ù„Ù…Ø®ØªÙ„ÙØ©": len(set(dates)),
                "Ù…Ø¹Ø¯Ù„_Ø§Ù„Ø£Ø­Ø¯Ø§Ø«_ÙÙŠ_Ø§Ù„Ø³Ø§Ø¹Ø©": len(lines) / 24 if times else 0
            }
        }

# ==========================
# ğŸŸ¢ Ù…ÙˆÙ„Ø¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
# ==========================
class ReportGenerator:
    """Ù…ÙˆÙ„Ø¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    @staticmethod
    def generate_text_report(basic_analysis: Dict[str, Any], suspicious_items: List[Dict[str, Any]],
                             stats: Dict[str, Any], analysis_time: float) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ù†ØµÙŠ Ù…ÙØµÙ„"""
        report = []
        report.append("â•”" + "â•" * 68 + "â•—")
        report.append("â•‘ ğŸ›¡  ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø±Ù‚Ù…ÙŠ - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© v2.0  â•‘")
        report.append("â•š" + "â•" * 68 + "â•")
        report.append(f"ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"â±ï¸  ÙˆÙ‚Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„: {analysis_time:.2f} Ø«Ø§Ù†ÙŠØ©")
        report.append("â”€" * 70)
        report.append("ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:")
        report.append(f"   â€¢ ğŸ“„ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø·Ø±: {basic_analysis['total_lines']:,}")
        report.append(f"   â€¢ âŒ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡: {basic_analysis['errors']}")
        report.append(f"   â€¢ âš ï¸  Ø¹Ø¯Ø¯ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª: {basic_analysis['warnings']}")
        report.append(f"   â€¢ â„¹ï¸  Ø£Ø­Ø¯Ø§Ø« Ù…Ø¹Ù„ÙˆÙ…Ø§Øª: {basic_analysis['info_events']}")
        report.append("â”€" * 70)

        if suspicious_items:
            report.append("ğŸ” Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ© (Ù…ØµÙ†ÙØ© Ø­Ø³Ø¨ Ø§Ù„Ø®Ø·ÙˆØ±Ø©):")
            threats_by_level: Dict[str, List[Dict[str, Any]]] = {}
            for item in suspicious_items:
                level = item['risk_level']
                threats_by_level.setdefault(level, []).append(item)
            for level in ["Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø®Ø·ÙˆØ±Ø©", "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·ÙˆØ±Ø©", "Ù…Ù†Ø®ÙØ¶ Ø§Ù„Ø®Ø·ÙˆØ±Ø©"]:
                if level in threats_by_level:
                    report.append(f"\n{threats_by_level[level][0]['risk_icon']} {level}:")
                    for threat in threats_by_level[level]:
                        report.append(f"   â€¢ {threat['name']} â† {threat['count']} Ù…Ø±Ø©")
                        report.append(f"     ğŸ“ {threat['description']}")
                        report.append(f"     ğŸ·  Ø§Ù„ØªØµÙ†ÙŠÙ: {threat['category']}")
                        report.append(f"     ğŸ“Š Ù†Ù‚Ø§Ø· Ø§Ù„Ø®Ø·ÙˆØ±Ø©: {threat['score']} Ù„ÙƒÙ„ Ø­Ø¯Ø«")
                        if threat.get('examples'):
                            report.append(f"     ğŸ” Ø£Ù…Ø«Ù„Ø©: {', '.join(threat['examples'][:2])}")
        else:
            report.append("âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙ‡Ø¯ÙŠØ¯Ø§Øª Ù…Ø´Ø¨ÙˆÙ‡Ø© Ù…ÙƒØªØ´ÙØ©")

        report.append("â”€" * 70)
        report.append("ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©:")
        for section, data in stats.items():
            report.append(f"\n   {section.replace('_', ' ')}:")
            for key, value in data.items():
                report.append(f"      â€¢ {key.replace('_', ' ')}: {value}")

        report.append("â”€" * 70)
        report.append("ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª:")
        risk_action = stats["ØªÙ‚ÙŠÙŠÙ…_Ø§Ù„Ø®Ø·ÙˆØ±Ø©"]["ÙŠØªØ·Ù„Ø¨_ØªØ¯Ø®Ù„"]
        if "ÙÙˆØ±ÙŠ" in risk_action:
            report.append("   ğŸš¨ ØªØ¯Ø®Ù„ ÙÙˆØ±ÙŠ Ù…Ø·Ù„ÙˆØ¨ - ØªÙ… Ø§ÙƒØªØ´Ø§Ù ØªÙ‡Ø¯ÙŠØ¯Ø§Øª Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø®Ø·ÙˆØ±Ø©")
            report.append("   ğŸ“ Ø§ØªØµÙ„ Ø¨ÙØ±ÙŠÙ‚ Ø§Ù„Ø£Ù…Ù† Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠ ÙÙˆØ±Ø§Ù‹")
        elif "Ù…Ø±Ø§Ù‚Ø¨Ø©" in risk_action:
            report.append("   ğŸ‘€ Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…Ø³ØªÙ…Ø±Ø© Ù…Ø·Ù„ÙˆØ¨Ø© - ØªÙ‡Ø¯ÙŠØ¯Ø§Øª Ù…ØªÙˆØ³Ø·Ø© Ø§Ù„Ø®Ø·ÙˆØ±Ø©")
            report.append("   ğŸ“Š ØªØªØ¨Ø¹ Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡")
        else:
            report.append("   âœ… Ø§Ù„ÙˆØ¶Ø¹ Ø·Ø¨ÙŠØ¹ÙŠ - Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙ‡Ø¯ÙŠØ¯Ø§Øª Ø®Ø·ÙŠØ±Ø©")

        report.append("â•”" + "â•" * 68 + "â•—")
        report.append("â•‘                    ğŸ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ØªÙ‚Ø±ÙŠØ±                     â•‘")
        report.append("â•š" + "â•" * 68 + "â•")
        return "\n".join(report)

    @staticmethod
    def save_report(report_text: str, output_dir: str = "results") -> Optional[str]:
        """Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ Ù…Ù„Ù"""
        try:
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = os.path.join(output_dir, f"forensic_report_{timestamp}.txt")
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(report_text)
            logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ: {filename}")
            return filename
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {e}")
            return None

# ==========================
# ğŸ§© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ==========================
def main():
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø£Ø¯Ø§Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø±Ù‚Ù…ÙŠ...")
    analyzer = ForensicAnalyzer()
    report_gen = ReportGenerator()

    # Ù…Ø«Ø§Ù„: ØªØ­Ù„ÙŠÙ„ Ù…Ù„Ù Ø§ÙØªØ±Ø§Ø¶ÙŠ
    file_path = "data/sample_log.txt"
    try:
        start_time = datetime.now()

        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
        read_result = analyzer.file_manager.read_file(file_path)
        if read_result["error"]:
            logger.error(f"âŒ Ø®Ø·Ø£: {read_result['error']}")
            print(f"âŒ Ø®Ø·Ø£: {read_result['error']}")
            return

        content = read_result["text"]
        basic_analysis = analyzer.analyze_log_basic(content)
        suspicious_items = analyzer.search_suspicious_patterns(content)
        advanced_stats = analyzer.advanced_statistical_analysis(content)

        analysis_time = (datetime.now() - start_time).total_seconds()
        report_text = report_gen.generate_text_report(basic_analysis, suspicious_items, advanced_stats, analysis_time)

        print("\n" + report_text)
        saved_file = report_gen.save_report(report_text)
        if saved_file:
            print(f"\nğŸ‰ Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­! Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù…Ø­ÙÙˆØ¸ ÙÙŠ: {saved_file}")

    except Exception as e:
        logger.exception("âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
        print(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")

if __name__ == "__main__":
    main()
