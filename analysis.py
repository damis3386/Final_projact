#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ÿ£ÿØÿßÿ© ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ¨ŸÜÿßÿ¶Ÿä ÿßŸÑÿ±ŸÇŸÖŸä - Digital Forensics Tool
ÿ•ÿµÿØÿßÿ±: 2.0
ÿßŸÑŸÖÿ∑Ÿàÿ±: ŸáŸäŸÑÿ© Ÿà ŸÑŸäŸÜ
"""

import os
import re
import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional

# --------------------------
# ÿ•ÿπÿØÿßÿØ ÿßŸÑŸÖÿ¨ŸÑÿØÿßÿ™ ÿßŸÑŸÑÿßÿ≤ŸÖÿ©
# --------------------------
os.makedirs("results", exist_ok=True)
os.makedirs("logs", exist_ok=True)
os.makedirs("data", exist_ok=True)   # ŸÑŸÑÿ™ÿ£ŸÉÿØ ŸÖŸÜ Ÿàÿ¨ŸàÿØ ŸÖÿ¨ŸÑÿØ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™
# --------------------------

# ==========================
# üîß ÿ•ÿπÿØÿßÿØ ÿßŸÑÿ™ÿ≥ÿ¨ŸäŸÑ (Logging)
# ==========================
LOG_PATH = os.path.join("logs", "forensics.log")
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_PATH, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==========================
# üéØ ÿßŸÑÿ´Ÿàÿßÿ®ÿ™ ŸàÿßŸÑÿ•ÿπÿØÿßÿØÿßÿ™
# ==========================
class Config:
    """ÿ•ÿπÿØÿßÿØÿßÿ™ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ"""
    SUPPORTED_EXTENSIONS = {'.log', '.txt', '.csv', '.json', '.zip'}
    MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
    RISK_THRESHOLDS = {
        'HIGH': 20,
        'MEDIUM': 10,
        'LOW': 0
    }

# ==========================
# üü¢ ÿ•ÿØÿßÿ±ÿ© ÿßŸÑŸÇŸàÿßÿπÿØ
# ==========================
class RuleManager:
    """ŸÖÿØŸäÿ± ŸÇŸàÿßÿπÿØ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ"""
    def __init__(self, rules_file: str = 'rules.json'):
        self.rules_file = rules_file
        self.rules = self._load_rules()

    def _load_rules(self) -> Dict[str, List[Dict[str, Any]]]:
        """ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑŸÇŸàÿßÿπÿØ ŸÖŸÜ ŸÖŸÑŸÅ JSON ÿ£Ÿà ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÇŸàÿßÿπÿØ ÿßŸÑÿßŸÅÿ™ÿ±ÿßÿ∂Ÿäÿ©"""
        try:
            if os.path.exists(self.rules_file):
                with open(self.rules_file, 'r', encoding='utf-8') as f:
                    rules = json.load(f)
                count = sum(len(v) for v in rules.values()) if isinstance(rules, dict) else 0
                logger.info(f"‚úÖ ÿ™ŸÖ ÿ™ÿ≠ŸÖŸäŸÑ {count} ŸÇÿßÿπÿØÿ© ŸÖŸÜ {self.rules_file}")
                return rules
            else:
                logger.warning(f"‚ö†Ô∏è  ŸÖŸÑŸÅ ÿßŸÑŸÇŸàÿßÿπÿØ {self.rules_file} ÿ∫Ÿäÿ± ŸÖŸàÿ¨ŸàÿØÿå ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÇŸàÿßÿπÿØ ÿßŸÑÿßŸÅÿ™ÿ±ÿßÿ∂Ÿäÿ©")
                return self._get_default_rules()
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå ÿÆÿ∑ÿ£ ŸÅŸä ÿ™ŸÜÿ≥ŸäŸÇ ŸÖŸÑŸÅ ÿßŸÑŸÇŸàÿßÿπÿØ: {e}")
            return self._get_default_rules()
        except Exception as e:
            logger.error(f"‚ùå ŸÅÿ¥ŸÑ ÿ™ÿ≠ŸÖŸäŸÑ ŸÇŸàÿßÿπÿØ: {e}")
            return self._get_default_rules()

    def _get_default_rules(self) -> Dict[str, List[Dict[str, Any]]]:
        """ÿßŸÑŸÇŸàÿßÿπÿØ ÿßŸÑÿßŸÅÿ™ÿ±ÿßÿ∂Ÿäÿ© (ŸÖŸàÿ≥ÿπÿ©)"""
        return {
            "high_risk_patterns": [
                {"name": "Ransomware", "pattern": r"\bransomware\b", "description": "ÿ®ÿ±ŸÖÿ¨Ÿäÿ© ŸÅÿØŸäÿ©", "score": 10, "category": "ÿ®ÿ±ÿßŸÖÿ¨ ÿ∂ÿßÿ±ÿ©"},
                {"name": "SQL Injection", "pattern": r"sql\s+injection|\binjection\b", "description": "ŸÖÿ≠ÿßŸàŸÑÿ© ÿ≠ŸÇŸÜ SQL", "score": 10, "category": "Ÿáÿ¨ŸàŸÖ ÿ™ÿ∑ÿ®ŸäŸÇŸä"},
                {"name": "Privilege Escalation", "pattern": r"privilege\s+escalation", "description": "ŸÖÿ≠ÿßŸàŸÑÿ© ÿ™ÿµÿπŸäÿØ ÿµŸÑÿßÿ≠Ÿäÿßÿ™", "score": 8, "category": "Ÿáÿ¨ŸàŸÖ ÿ™ÿ∑ÿ®ŸäŸÇŸä"}
            ],
            "medium_risk_patterns": [
                {"name": "Malware", "pattern": r"\bmalware\b|\bvirus\b|\btrojan\b", "description": "ÿ®ÿ±ÿßŸÖÿ¨ ÿ∂ÿßÿ±ÿ©", "score": 5, "category": "ÿ®ÿ±ÿßŸÖÿ¨ ÿ∂ÿßÿ±ÿ©"},
                {"name": "Unauthorized Access", "pattern": r"\bunauthorized\b|\bunauthorized\s+access\b", "description": "ŸàÿµŸàŸÑ ÿ∫Ÿäÿ± ŸÖÿµÿ±ÿ≠ ÿ®Ÿá", "score": 5, "category": "ÿ£ŸÖŸÜ ÿßŸÑÿ¥ÿ®ŸÉÿßÿ™"},
                {"name": "Failed Login", "pattern": r"\bfailed\s+login\b|\blogin\s+failed\b|\bauthentication\s+failed\b", "description": "ŸÖÿ≠ÿßŸàŸÑÿßÿ™ ÿØÿÆŸàŸÑ ŸÅÿßÿ¥ŸÑÿ©", "score": 5, "category": "ÿ£ŸÖÿßŸÜ ÿßŸÑŸÜÿ∏ÿßŸÖ"},
                {"name": "Brute Force Pattern", "pattern": r"(failed\s+login.*){3,}", "description": "ŸÜŸÖÿ∑ Ÿäÿ¥Ÿäÿ± ÿ•ŸÑŸâ Ÿáÿ¨ŸàŸÖ ÿ™ÿÆŸÖŸäŸÜ ŸÖÿ™ŸÉÿ±ÿ±", "score": 6, "category": "Ÿáÿ¨ŸàŸÖ ÿ¥ÿ®ŸÉŸä"}
            ],
            "low_risk_patterns": [
                {"name": "Warning", "pattern": r"\bwarning\b", "description": "ÿ™ÿ≠ÿ∞Ÿäÿ± ŸÜÿ∏ÿßŸÖ", "score": 1, "category": "ŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑŸÜÿ∏ÿßŸÖ"},
                {"name": "Timeout", "pattern": r"\btimeout\b|\btime\s?out\b", "description": "ÿßŸÜÿ™Ÿáÿßÿ° ŸÖŸáŸÑÿ© ÿßÿ™ÿµÿßŸÑ", "score": 1, "category": "ÿ£ÿØÿßÿ° ÿßŸÑŸÜÿ∏ÿßŸÖ"},
                {"name": "Scan", "pattern": r"\bscan\b|\bscanning\b", "description": "ŸÜÿ¥ÿßÿ∑ ŸÅÿ≠ÿµ/ŸÖÿ≥ÿ≠", "score": 1, "category": "ŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑÿ¥ÿ®ŸÉÿ©"}
            ]
        }

    def get_all_rules(self) -> Dict[str, List[Dict[str, Any]]]:
        """ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÇŸàÿßÿπÿØ"""
        return self.rules

# ==========================
# üü¢ ÿ•ÿØÿßÿ±ÿ© ÿßŸÑŸÖŸÑŸÅÿßÿ™
# ==========================
import io
import zipfile
import csv

class FileManager:
    """ŸÖÿØŸäÿ± ÿπŸÖŸÑŸäÿßÿ™ ÿßŸÑŸÖŸÑŸÅÿßÿ™ ‚Äî ŸäÿØÿπŸÖ txt/csv/json/zip (ŸÖÿ≠ÿ™ŸàŸâ ŸÜÿµŸä)"""
    @staticmethod
    def read_file(file_path: str, encoding: str = 'utf-8') -> Dict[str, Optional[object]]:
        """
        ŸäŸéÿ±ÿ¨ÿπ dict:
        { "text": str|None, "meta": {...}, "error": None|str }
        """
        try:
            if not os.path.exists(file_path):
                return {"text": None, "meta": None, "error": f"ÿßŸÑŸÖŸÑŸÅ ÿ∫Ÿäÿ± ŸÖŸàÿ¨ŸàÿØ: {file_path}"}
            size = os.path.getsize(file_path)
            if size > Config.MAX_FILE_SIZE:
                return {"text": None, "meta": None, "error": f"ÿ≠ÿ¨ŸÖ ÿßŸÑŸÖŸÑŸÅ ŸÉÿ®Ÿäÿ± ÿ¨ÿØÿßŸã: {size} ÿ®ÿßŸäÿ™"}
            name = os.path.basename(file_path)
            _, ext = os.path.splitext(name.lower())
            meta = {"path": file_path, "size": size, "ext": ext, "files_in_archive": None}

            if ext in ('.txt', '.log'):
                with open(file_path, 'r', encoding=encoding, errors='replace') as f:
                    text = f.read()
                logger.info(f"üìñ ÿ™ŸÖ ŸÇÿ±ÿßÿ°ÿ© ÿßŸÑŸÖŸÑŸÅ: {file_path} ({size} ÿ®ÿßŸäÿ™ÿå {len(text.splitlines())} ÿ≥ÿ∑ÿ±)")
                return {"text": text, "meta": meta, "error": None}

            if ext == '.csv':
                rows = []
                with open(file_path, 'r', encoding=encoding, errors='replace', newline='') as f:
                    reader = csv.DictReader(f)
                    for r in reader:
                        rows.append(json.dumps(r, ensure_ascii=False))
                text = "\n".join(rows)
                return {"text": text, "meta": meta, "error": None}

            if ext == '.json':
                with open(file_path, 'r', encoding=encoding, errors='replace') as f:
                    data = json.load(f)
                if isinstance(data, list):
                    text = "\n".join(json.dumps(it, ensure_ascii=False) for it in data)
                else:
                    text = json.dumps(data, ensure_ascii=False)
                return {"text": text, "meta": meta, "error": None}

            if ext == '.zip':
                contents = []
                names = []
                with zipfile.ZipFile(file_path, 'r') as z:
                    for info in z.infolist():
                        names.append(info.filename)
                        _, e = os.path.splitext(info.filename.lower())
                        if e in ('.txt', '.log'):
                            try:
                                with z.open(info) as f:
                                    data = f.read().decode(encoding, errors='replace')
                                contents.append(f"--- FILE: {info.filename} ---\n{data}")
                            except Exception:
                                contents.append(f"--- FILE: {info.filename} (unreadable) ---")
                        elif e == '.csv':
                            try:
                                with z.open(info) as f:
                                    text = f.read().decode(encoding, errors='replace')
                                reader = csv.DictReader(io.StringIO(text))
                                rows = [json.dumps(r, ensure_ascii=False) for r in reader]
                                contents.append("\n".join(rows))
                            except Exception:
                                contents.append(f"--- FILE: {info.filename} (csv parse error) ---")
                        elif e == '.json':
                            try:
                                with z.open(info) as f:
                                    text = f.read().decode(encoding, errors='replace')
                                    data = json.loads(text)
                                if isinstance(data, list):
                                    contents.append("\n".join(json.dumps(it, ensure_ascii=False) for it in data))
                                else:
                                    contents.append(json.dumps(data, ensure_ascii=False))
                            except Exception:
                                contents.append(f"--- FILE: {info.filename} (json parse error) ---")
                        else:
                            contents.append(f"--- FILE: {info.filename} (skipped - unsupported) ---")
                meta["files_in_archive"] = names
                return {"text": "\n\n".join(contents), "meta": meta, "error": None}

            return {"text": None, "meta": meta, "error": f"Unsupported extension: {ext}"}

        except UnicodeDecodeError:
            try:
                with open(file_path, 'r', encoding='latin-1') as f:
                    text = f.read()
                return {"text": text, "meta": meta, "error": None}
            except Exception as e:
                return {"text": None, "meta": None, "error": str(e)}
        except Exception as e:
            logger.error(f"‚ùå ÿÆÿ∑ÿ£ ŸÅŸä ŸÇÿ±ÿßÿ°ÿ© ÿßŸÑŸÖŸÑŸÅ: {e}")
            return {"text": None, "meta": None, "error": str(e)}

# ==========================
# üü¢ ÿßŸÑŸÖÿ≠ŸÑŸÑ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä
# ==========================
class ForensicAnalyzer:
    """ÿßŸÑŸÖÿ≠ŸÑŸÑ ÿßŸÑÿ¨ŸÜÿßÿ¶Ÿä ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä"""
    def __init__(self, rules_file: str = 'rules.json'):
        self.rule_manager = RuleManager(rules_file=rules_file)
        self.file_manager = FileManager()

    def analyze_log_basic(self, content: str) -> Dict[str, Any]:
        """ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿä ŸÑŸÑÿ≥ÿ¨ŸÑÿßÿ™"""
        lines = content.splitlines()
        error_lines = [line for line in lines if re.search(r'\berror\b', line, re.IGNORECASE)]
        warning_lines = [line for line in lines if re.search(r'\bwarning\b', line, re.IGNORECASE)]
        info_lines = [line for line in lines if re.search(r'\binfo\b', line, re.IGNORECASE)]
        return {
            "total_lines": len(lines),
            "errors": len(error_lines),
            "warnings": len(warning_lines),
            "info_events": len(info_lines),
            "analysis_timestamp": datetime.now().isoformat()
        }

    def search_suspicious_patterns(self, content: str) -> List[Dict[str, Any]]:
        """ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ÿßŸÑÿ£ŸÜŸÖÿßÿ∑ ÿßŸÑŸÖÿ¥ÿ®ŸàŸáÿ© ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÇŸàÿßÿπÿØ"""
        rules = self.rule_manager.get_all_rules()
        found_items: List[Dict[str, Any]] = []
        risk_levels_mapping = {
            "high_risk_patterns": {"icon": "üü•", "level": "ÿπÿßŸÑŸä ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©"},
            "medium_risk_patterns": {"icon": "üü®", "level": "ŸÖÿ™Ÿàÿ≥ÿ∑ ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©"},
            "low_risk_patterns": {"icon": "üü©", "level": "ŸÖŸÜÿÆŸÅÿ∂ ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©"}
        }

        for rule_category, risk_info in risk_levels_mapping.items():
            for rule in rules.get(rule_category, []):
                try:
                    matches = re.findall(rule['pattern'], content, flags=re.IGNORECASE)
                except re.error as e:
                    logger.error(f"‚ùå ÿÆÿ∑ÿ£ ŸÅŸä ÿßŸÑŸÜŸÖÿ∑ {rule.get('pattern')}: {e}")
                    matches = []
                if matches:
                    examples = []
                    # ÿ•ÿ∞ÿß ŸÉÿßŸÜÿ™ ÿßŸÑŸÄ matches ÿπÿ®ÿßÿ±ÿ© ÿπŸÜ tuples ÿ£Ÿà ŸÇŸàÿßÿ¶ŸÖ ÿ®ÿ≥ÿ®ÿ® ŸÖÿ¨ŸÖŸàÿπÿßÿ™ ÿßŸÑÿ™ŸÇÿßÿ∑ ŸÅŸä ÿßŸÑ regex
                    for m in matches[:3]:
                        if isinstance(m, (list, tuple)):
                            examples.append(" ".join([str(x) for x in m if x]))
                        else:
                            examples.append(str(m))
                    found_items.append({
                        "risk_icon": risk_info["icon"],
                        "risk_level": risk_info["level"],
                        "name": rule.get('name'),
                        "pattern": rule.get('pattern'),
                        "count": len(matches),
                        "score": rule.get('score', 1),
                        "description": rule.get('description', 'ŸÑÿß ŸäŸàÿ¨ÿØ ŸàÿµŸÅ'),
                        "category": rule.get('category', 'ÿ∫Ÿäÿ± ŸÖÿµŸÜŸÅ'),
                        "examples": examples,
                        "first_occurrence": examples[0] if examples else ""
                    })
                    logger.info(f"üîç ÿπŸèÿ´ÿ± ÿπŸÑŸâ: {rule.get('name')} ({len(matches)} ŸÖÿ±ÿ©)")
        # ÿ™ÿ±ÿ™Ÿäÿ® ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿ≠ÿ≥ÿ® ÿßŸÑŸÜŸÇÿßÿ∑ (score * count) ÿ™ŸÜÿßÿ≤ŸÑŸäÿßŸã
        found_items.sort(key=lambda x: x['score'] * x['count'], reverse=True)
        return found_items

    def advanced_statistical_analysis(self, content: str) -> Dict[str, Any]:
        """ÿ™ÿ≠ŸÑŸäŸÑ ÿ•ÿ≠ÿµÿßÿ¶Ÿä ŸÖÿ™ŸÇÿØŸÖ"""
        lines = content.splitlines()
        # ÿ£ŸÜŸÖÿßÿ∑ ÿßŸÑÿ™ŸàŸÇŸäÿ™ ŸàÿßŸÑÿ™Ÿàÿßÿ±ŸäÿÆ ŸàÿπŸÜÿßŸàŸäŸÜ IP Ÿà URLs
        times = re.findall(r'(\d{1,2}:\d{2}:\d{2})', content)
        dates = re.findall(r'(\d{4}-\d{2}-\d{2}|\d{2}/\d{2}/\d{4})', content)
        ips = re.findall(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', content)
        urls = re.findall(r'https?://[^\s]+', content)
        suspicious_patterns = self.search_suspicious_patterns(content)
        total_risk_score = sum(item['score'] * item['count'] for item in suspicious_patterns)

        if total_risk_score >= Config.RISK_THRESHOLDS['HIGH']:
            overall_risk = "üü• ÿπÿßŸÑŸä"
            action_required = "ŸÜÿπŸÖ - ÿ™ÿØÿÆŸÑ ŸÅŸàÿ±Ÿä ŸÖÿ∑ŸÑŸàÿ®"
        elif total_risk_score >= Config.RISK_THRESHOLDS['MEDIUM']:
            overall_risk = "üü® ŸÖÿ™Ÿàÿ≥ÿ∑"
            action_required = "ŸÖÿ±ÿßŸÇÿ®ÿ© ŸÖÿ≥ÿ™ŸÖÿ±ÿ©"
        else:
            overall_risk = "üü© ŸÖŸÜÿÆŸÅÿ∂"
            action_required = "ŸÑÿß - ÿ∂ŸÖŸÜ ÿßŸÑŸÖÿπÿØŸÑ ÿßŸÑÿ∑ÿ®ŸäÿπŸä"

        return {
            "ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ_ÿßŸÑÿ≤ŸÖŸÜŸä": {
                "ÿ£ŸàŸÑ_ÿ≠ÿØÿ´": times[0] if times else "ÿ∫Ÿäÿ± ŸÖÿπÿ±ŸàŸÅ",
                "ÿ¢ÿÆÿ±_ÿ≠ÿØÿ´": times[-1] if times else "ÿ∫Ÿäÿ± ŸÖÿπÿ±ŸàŸÅ",
                "ÿßŸÑŸÅÿ™ÿ±ÿ©_ÿßŸÑÿ≤ŸÖŸÜŸäÿ©": f"{times[0]} - {times[-1]}" if times else "ÿ∫Ÿäÿ± ŸÖÿπÿ±ŸàŸÅ",
                "ÿπÿØÿØ_ÿßŸÑÿ£ŸàŸÇÿßÿ™_ÿßŸÑŸÖÿ≥ÿ¨ŸÑÿ©": len(times)
            },
            "ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ_ÿßŸÑÿ¥ÿ®ŸÉŸä": {
                "ÿπŸÜÿßŸàŸäŸÜ_IP_ŸÖÿÆÿ™ŸÑŸÅÿ©": len(set(ips)),
                "ÿ•ÿ¨ŸÖÿßŸÑŸä_ÿπŸÜÿßŸàŸäŸÜ_IP": len(ips),
                "ÿπŸÜÿßŸàŸäŸÜ_URL_ŸÖŸÉÿ™ÿ¥ŸÅÿ©": len(urls)
            },
            "ÿ™ŸÇŸäŸäŸÖ_ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©": {
                "ŸÜŸÇÿßÿ∑_ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©_ÿßŸÑÿ•ÿ¨ŸÖÿßŸÑŸäÿ©": total_risk_score,
                "ŸÖÿ≥ÿ™ŸàŸâ_ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©_ÿßŸÑÿ¥ÿßŸÖŸÑ": overall_risk,
                "Ÿäÿ™ÿ∑ŸÑÿ®_ÿ™ÿØÿÆŸÑ": action_required,
                "ÿπÿØÿØ_ÿßŸÑÿ™ŸáÿØŸäÿØÿßÿ™_ÿßŸÑŸÖŸÉÿ™ÿ¥ŸÅÿ©": len(suspicious_patterns)
            },
            "ÿßŸÑÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™_ÿßŸÑÿπÿßŸÖÿ©": {
                "ÿ•ÿ¨ŸÖÿßŸÑŸä_ÿßŸÑÿ£ÿ≠ÿØÿßÿ´": len(lines),
                "ÿßŸÑÿ™Ÿàÿßÿ±ŸäÿÆ_ÿßŸÑŸÖÿÆÿ™ŸÑŸÅÿ©": len(set(dates)),
                "ŸÖÿπÿØŸÑ_ÿßŸÑÿ£ÿ≠ÿØÿßÿ´_ŸÅŸä_ÿßŸÑÿ≥ÿßÿπÿ©": len(lines) / 24 if times else 0
            }
        }

# ==========================
# üü¢ ŸÖŸàŸÑÿØ ÿßŸÑÿ™ŸÇÿßÿ±Ÿäÿ±
# ==========================
class ReportGenerator:
    """ŸÖŸàŸÑÿØ ÿßŸÑÿ™ŸÇÿßÿ±Ÿäÿ± ÿßŸÑŸÖÿ™ŸÇÿØŸÖ"""
    @staticmethod
    def generate_text_report(basic_analysis: Dict[str, Any], suspicious_items: List[Dict[str, Any]],
                             stats: Dict[str, Any], analysis_time: float) -> str:
        """ÿ™ŸàŸÑŸäÿØ ÿ™ŸÇÿ±Ÿäÿ± ŸÜÿµŸä ŸÖŸÅÿµŸÑ"""
        report = []
        report.append("‚ïî" + "‚ïê" * 68 + "‚ïó")
        report.append("‚ïë üõ°  ÿ™ŸÇÿ±Ÿäÿ± ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ¨ŸÜÿßÿ¶Ÿä ÿßŸÑÿ±ŸÇŸÖŸä - ÿßŸÑŸÜÿ≥ÿÆÿ© ÿßŸÑÿßÿ≠ÿ™ÿ±ÿßŸÅŸäÿ© v2.0  ‚ïë")
        report.append("‚ïö" + "‚ïê" * 68 + "‚ïù")
        report.append(f"üìÖ ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ™ŸÇÿ±Ÿäÿ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"‚è±Ô∏è  ŸàŸÇÿ™ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ: {analysis_time:.2f} ÿ´ÿßŸÜŸäÿ©")
        report.append("‚îÄ" * 70)
        report.append("üìä ÿßŸÑŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©:")
        report.append(f"   ‚Ä¢ üìÑ ÿ•ÿ¨ŸÖÿßŸÑŸä ÿßŸÑÿ£ÿ≥ÿ∑ÿ±: {basic_analysis['total_lines']:,}")
        report.append(f"   ‚Ä¢ ‚ùå ÿπÿØÿØ ÿßŸÑÿ£ÿÆÿ∑ÿßÿ°: {basic_analysis['errors']}")
        report.append(f"   ‚Ä¢ ‚ö†Ô∏è  ÿπÿØÿØ ÿßŸÑÿ™ÿ≠ÿ∞Ÿäÿ±ÿßÿ™: {basic_analysis['warnings']}")
        report.append(f"   ‚Ä¢ ‚ÑπÔ∏è  ÿ£ÿ≠ÿØÿßÿ´ ŸÖÿπŸÑŸàŸÖÿßÿ™: {basic_analysis['info_events']}")
        report.append("‚îÄ" * 70)

        if suspicious_items:
            report.append("üîç ÿßŸÑÿ™ŸáÿØŸäÿØÿßÿ™ ÿßŸÑŸÖŸÉÿ™ÿ¥ŸÅÿ© (ŸÖÿµŸÜŸÅÿ© ÿ≠ÿ≥ÿ® ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©):")
            threats_by_level: Dict[str, List[Dict[str, Any]]] = {}
            for item in suspicious_items:
                level = item['risk_level']
                threats_by_level.setdefault(level, []).append(item)
            for level in ["ÿπÿßŸÑŸä ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©", "ŸÖÿ™Ÿàÿ≥ÿ∑ ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©", "ŸÖŸÜÿÆŸÅÿ∂ ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©"]:
                if level in threats_by_level:
                    report.append(f"\n{threats_by_level[level][0]['risk_icon']} {level}:")
                    for threat in threats_by_level[level]:
                        report.append(f"   ‚Ä¢ {threat['name']} ‚Üê {threat['count']} ŸÖÿ±ÿ©")
                        report.append(f"     üìù {threat['description']}")
                        report.append(f"     üè∑  ÿßŸÑÿ™ÿµŸÜŸäŸÅ: {threat['category']}")
                        report.append(f"     üìä ŸÜŸÇÿßÿ∑ ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©: {threat['score']} ŸÑŸÉŸÑ ÿ≠ÿØÿ´")
                        if threat.get('examples'):
                            report.append(f"     üîç ÿ£ŸÖÿ´ŸÑÿ©: {', '.join(threat['examples'][:2])}")
        else:
            report.append("‚úÖ ŸÑÿß ÿ™Ÿàÿ¨ÿØ ÿ™ŸáÿØŸäÿØÿßÿ™ ŸÖÿ¥ÿ®ŸàŸáÿ© ŸÖŸÉÿ™ÿ¥ŸÅÿ©")

        report.append("‚îÄ" * 70)
        report.append("üìà ÿßŸÑÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿßŸÑŸÖÿ™ŸÇÿØŸÖÿ©:")
        for section, data in stats.items():
            report.append(f"\n   {section.replace('_', ' ')}:")
            for key, value in data.items():
                report.append(f"      ‚Ä¢ {key.replace('_', ' ')}: {value}")

        report.append("‚îÄ" * 70)
        report.append("üí° ÿßŸÑÿ™ŸàÿµŸäÿßÿ™:")
        risk_action = stats["ÿ™ŸÇŸäŸäŸÖ_ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©"]["Ÿäÿ™ÿ∑ŸÑÿ®_ÿ™ÿØÿÆŸÑ"]
        if "ŸÅŸàÿ±Ÿä" in risk_action:
            report.append("   üö® ÿ™ÿØÿÆŸÑ ŸÅŸàÿ±Ÿä ŸÖÿ∑ŸÑŸàÿ® - ÿ™ŸÖ ÿßŸÉÿ™ÿ¥ÿßŸÅ ÿ™ŸáÿØŸäÿØÿßÿ™ ÿπÿßŸÑŸäÿ© ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©")
            report.append("   üìû ÿßÿ™ÿµŸÑ ÿ®ŸÅÿ±ŸäŸÇ ÿßŸÑÿ£ŸÖŸÜ ÿßŸÑÿ≥Ÿäÿ®ÿ±ÿßŸÜŸä ŸÅŸàÿ±ÿßŸã")
        elif "ŸÖÿ±ÿßŸÇÿ®ÿ©" in risk_action:
            report.append("   üëÄ ŸÖÿ±ÿßŸÇÿ®ÿ© ŸÖÿ≥ÿ™ŸÖÿ±ÿ© ŸÖÿ∑ŸÑŸàÿ®ÿ© - ÿ™ŸáÿØŸäÿØÿßÿ™ ŸÖÿ™Ÿàÿ≥ÿ∑ÿ© ÿßŸÑÿÆÿ∑Ÿàÿ±ÿ©")
            report.append("   üìä ÿ™ÿ™ÿ®ÿπ ÿßŸÑŸÜÿ¥ÿßÿ∑ ÿßŸÑŸÖÿ¥ÿ®ŸàŸá")
        else:
            report.append("   ‚úÖ ÿßŸÑŸàÿ∂ÿπ ÿ∑ÿ®ŸäÿπŸä - ŸÑÿß ÿ™Ÿàÿ¨ÿØ ÿ™ŸáÿØŸäÿØÿßÿ™ ÿÆÿ∑Ÿäÿ±ÿ©")

        report.append("‚ïî" + "‚ïê" * 68 + "‚ïó")
        report.append("‚ïë                    üèÅ ŸÜŸáÿßŸäÿ© ÿßŸÑÿ™ŸÇÿ±Ÿäÿ±                     ‚ïë")
        report.append("‚ïö" + "‚ïê" * 68 + "‚ïù")
        return "\n".join(report)

    @staticmethod
    def save_report(report_text: str, output_dir: str = "results") -> Optional[str]:
        """ÿ≠ŸÅÿ∏ ÿßŸÑÿ™ŸÇÿ±Ÿäÿ± ŸÅŸä ŸÖŸÑŸÅ"""
        try:
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = os.path.join(output_dir, f"forensic_report_{timestamp}.txt")
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(report_text)
            logger.info(f"üíæ ÿ™ŸÖ ÿ≠ŸÅÿ∏ ÿßŸÑÿ™ŸÇÿ±Ÿäÿ± ŸÅŸä: {filename}")
            return filename
        except Exception as e:
            logger.error(f"‚ùå ŸÅÿ¥ŸÑ ÿ≠ŸÅÿ∏ ÿßŸÑÿ™ŸÇÿ±Ÿäÿ±: {e}")
            return None

# ==========================
# üß© ÿßŸÑÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä
# ==========================
def main():
    print("üöÄ ÿ®ÿØÿ° ÿ£ÿØÿßÿ© ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ¨ŸÜÿßÿ¶Ÿä ÿßŸÑÿ±ŸÇŸÖŸä...")
    analyzer = ForensicAnalyzer()
    report_gen = ReportGenerator()

    # ŸÖÿ´ÿßŸÑ: ÿ™ÿ≠ŸÑŸäŸÑ ŸÖŸÑŸÅ ÿßŸÅÿ™ÿ±ÿßÿ∂Ÿä
    file_path = "data/sample_log.txt"
    try:
        start_time = datetime.now()

        # ŸÇÿ±ÿßÿ°ÿ© ÿßŸÑŸÖŸÑŸÅ
        read_result = analyzer.file_manager.read_file(file_path)
        if read_result["error"]:
            logger.error(f"‚ùå ÿÆÿ∑ÿ£: {read_result['error']}")
            print(f"‚ùå ÿÆÿ∑ÿ£: {read_result['error']}")
            return

        content = read_result["text"]
        basic_analysis = analyzer.analyze_log_basic(content)
        suspicious_items = analyzer.search_suspicious_patterns(content)
        advanced_stats = analyzer.advanced_statistical_analysis(content)

        analysis_time = (datetime.now() - start_time).total_seconds()
        report_text = report_gen.generate_text_report(basic_analysis, suspicious_items, advanced_stats, analysis_time)

        print("\n" + report_text)
        saved_file = report_gen.save_report(report_text)
        if saved_file:
            print(f"\nüéâ ÿßŸÉÿ™ŸÖŸÑ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿ®ŸÜÿ¨ÿßÿ≠! ÿßŸÑÿ™ŸÇÿ±Ÿäÿ± ŸÖÿ≠ŸÅŸàÿ∏ ŸÅŸä: {saved_file}")

    except Exception as e:
        logger.exception("‚ùå ŸÅÿ¥ŸÑ ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ:")
        print(f"‚ùå ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£: {e}")

if __name__ == "__main__":
    main()
