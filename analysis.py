#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø£Ø¯Ø§Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø±Ù‚Ù…ÙŠ - Digital Forensics Tool
Ø¥ØµØ¯Ø§Ø±: 2.0
Ø§Ù„Ù…Ø·ÙˆØ±: Ù‡ÙŠÙ„Ø© Ù„ÙŠÙ†
"""

import os
import re
import json
import logging
from datetime import datetime
from typing import Dict, List, Any

# ==========================
# ğŸ”§ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Logging)
# ==========================
os.makedirs("logs", exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/forensics.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==========================
# ğŸ¯ Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# ==========================
class Config:
    """Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"""
    SUPPORTED_EXTENSIONS = {'.log', '.txt', '.csv'}
    MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB
    RISK_THRESHOLDS = {
        'HIGH': 20,
        'MEDIUM': 10,
        'LOW': 0
    }

# ==========================
# ğŸŸ¢ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯
# ==========================
class RuleManager:
    """Ù…Ø¯ÙŠØ± Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
    
    def __init__(self, rules_file: str = 'rules.json'):
        self.rules_file = rules_file
        self.rules = self._load_rules()
    
    def _load_rules(self) -> Dict[str, List[Dict]]:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù† Ù…Ù„Ù JSON"""
        try:
            with open(self.rules_file, 'r', encoding='utf-8') as f:
                rules = json.load(f)
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {sum(len(v) for v in rules.values())} Ù‚Ø§Ø¹Ø¯Ø© Ù…Ù† {self.rules_file}")
                return rules
        except FileNotFoundError:
            logger.warning(f"âš ï¸  Ù…Ù„Ù Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ {self.rules_file} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©")
            return self._get_default_rules()
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø³ÙŠÙ‚ Ù…Ù„Ù Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯: {e}")
            return self._get_default_rules()
    
    def _get_default_rules(self) -> Dict[str, List[Dict]]:
        """Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø·ÙˆØ§Ø±Ø¦"""
        return {
            "high_risk_patterns": [
                {"name": "SQL Injection", "pattern": r"sql\s+injection", "description": "Ù…Ø­Ø§ÙˆÙ„Ø© Ø­Ù‚Ù† Ø£ÙˆØ§Ù…Ø± SQL Ø®Ø¨ÙŠØ«Ø©", "score": 10, "category": "Ù‡Ø¬ÙˆÙ… ØªØ·Ø¨ÙŠÙ‚ÙŠ"},
                {"name": "Ransomware", "pattern": r"ransomware", "description": "Ø§ÙƒØªØ´Ø§Ù Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„ÙØ¯ÙŠØ©", "score": 10, "category": "Ø¨Ø±Ø§Ù…Ø¬ Ø¶Ø§Ø±Ø©"}
            ],
            "medium_risk_patterns": [
                {"name": "Failed Login", "pattern": r"failed\s+login", "description": "Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø¯Ø®ÙˆÙ„ ÙØ§Ø´Ù„Ø© Ù…ØªÙƒØ±Ø±Ø©", "score": 5, "category": "Ø£Ù…Ø§Ù† Ø§Ù„Ù†Ø¸Ø§Ù…"},
                {"name": "Malware", "pattern": r"malware", "description": "Ø¨Ø±Ø§Ù…Ø¬ Ø¶Ø§Ø±Ø©", "score": 5, "category": "Ø¨Ø±Ø§Ù…Ø¬ Ø¶Ø§Ø±Ø©"},
                {"name": "Unauthorized Access", "pattern": r"unauthorized\s+access", "description": "ÙˆØµÙˆÙ„ ØºÙŠØ± Ù…ØµØ±Ø­ Ø¨Ù‡", "score": 5, "category": "Ø£Ù…Ø§Ù† Ø§Ù„Ù†Ø¸Ø§Ù…"}
            ],
            "low_risk_patterns": [
                {"name": "Warning", "pattern": r"warning", "description": "ØªØ­Ø°ÙŠØ±Ø§Øª Ù†Ø¸Ø§Ù…", "score": 1, "category": "Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"},
                {"name": "Timeout", "pattern": r"timeout", "description": "Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù‡Ù„Ø© Ø§ØªØµØ§Ù„", "score": 1, "category": "Ø£Ù…Ø§Ù† Ø§Ù„Ø´Ø¨ÙƒØ©"}
            ]
        }
    
    def get_all_rules(self) -> Dict[str, List[Dict]]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯"""
        return self.rules
# ==========================
# ğŸŸ¢ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù„ÙØ§Øª
# ==========================
class FileManager:
    """Ù…Ø¯ÙŠØ± Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ù„ÙØ§Øª"""
    
    @staticmethod
    def read_file(file_path: str) -> str:
        """Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"""
        try:
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {file_path}")
            
            file_size = os.path.getsize(file_path)
            if file_size > Config.MAX_FILE_SIZE:
                raise ValueError(f"Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹: {file_size} Ø¨Ø§ÙŠØª")
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            logger.info(f"ğŸ“– ØªÙ… Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {file_path} ({file_size} Ø¨Ø§ÙŠØªØŒ {len(content.splitlines())} Ø³Ø·Ø±)")
            return content
        except UnicodeDecodeError:
            with open(file_path, 'r', encoding='latin-1') as f:
                content = f.read()
            logger.warning("âš ï¸  ØªÙ… Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø¨ØªØ´ÙÙŠØ± latin-1")
            return content
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
            raise

# ==========================
# ğŸŸ¢ Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ==========================
class ForensicAnalyzer:
    """Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø¬Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    
    def __init__(self):
        self.rule_manager = RuleManager()
        self.file_manager = FileManager()
    
    def analyze_log_basic(self, content: str) -> Dict[str, Any]:
        """Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ø³Ø¬Ù„Ø§Øª"""
        lines = content.splitlines()
        error_lines = [line for line in lines if re.search(r'\berror\b', line, re.IGNORECASE)]
        warning_lines = [line for line in lines if re.search(r'\bwarning\b', line, re.IGNORECASE)]
        info_lines = [line for line in lines if re.search(r'\binfo\b', line, re.IGNORECASE)]
        return {
            "total_lines": len(lines),
            "errors": len(error_lines),
            "warnings": len(warning_lines),
            "info_events": len(info_lines),
            "analysis_timestamp": datetime.now().isoformat()
        }
    
    def search_suspicious_patterns(self, content: str) -> List[Dict[str, Any]]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯"""
        rules = self.rule_manager.get_all_rules()
        found_items = []
        risk_levels_mapping = {
            "high_risk_patterns": {"icon": "ğŸŸ¥", "level": "Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø®Ø·ÙˆØ±Ø©"},
            "medium_risk_patterns": {"icon": "ğŸŸ ", "level": "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·ÙˆØ±Ø©"},
            "low_risk_patterns": {"icon": "ğŸŸ¢", "level": "Ù…Ù†Ø®ÙØ¶ Ø§Ù„Ø®Ø·ÙˆØ±Ø©"}
        }
        for rule_category, risk_info in risk_levels_mapping.items():
            for rule in rules.get(rule_category, []):
                try:
                    matches = re.findall(rule['pattern'], content, re.IGNORECASE)
                    if matches:
                        found_items.append({
                            "risk_icon": risk_info["icon"],
                            "risk_level": risk_info["level"],
                            "name": rule['name'],
                            "pattern": rule['pattern'],
                            "count": len(matches),
                            "score": rule.get('score', 1),
                            "description": rule.get('description', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙˆØµÙ'),
                            "category": rule.get('category', 'ØºÙŠØ± Ù…ØµÙ†Ù'),
                            "examples": matches[:3],
                            "first_occurrence": matches[0] if matches else ""
                        })
                        logger.info(f"ğŸ” Ø¹ÙØ«Ø± Ø¹Ù„Ù‰: {rule['name']} ({len(matches)} Ù…Ø±Ø©)")
                except re.error as e:
                    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ù…Ø· {rule['pattern']}: {e}")
        return sorted(found_items, key=lambda x: x['score'], reverse=True)
    
    def advanced_statistical_analysis(self, content: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠ Ù…ØªÙ‚Ø¯Ù…"""
        lines = content.splitlines()
        times = re.findall(r'(\d{1,2}:\d{2}:\d{2})', content)
        dates = re.findall(r'(\d{4}-\d{2}-\d{2}|\d{2}/\d{2}/\d{4})', content)
        ips = re.findall(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', content)
        urls = re.findall(r'https?://[^\s]+', content)
        suspicious_patterns = self.search_suspicious_patterns(content)
        total_risk_score = sum(item['score'] * item['count'] for item in suspicious_patterns)
        
        if total_risk_score >= Config.RISK_THRESHOLDS['HIGH']:
            overall_risk = "ğŸŸ¥ Ø¹Ø§Ù„ÙŠ"
            action_required = "Ù†Ø¹Ù… - ØªØ¯Ø®Ù„ ÙÙˆØ±ÙŠ Ù…Ø·Ù„ÙˆØ¨"
        elif total_risk_score >= Config.RISK_THRESHOLDS['MEDIUM']:
            overall_risk = "ğŸŸ  Ù…ØªÙˆØ³Ø·"
            action_required = "Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…Ø³ØªÙ…Ø±Ø©"
        else:
            overall_risk = "ğŸŸ¢ Ù…Ù†Ø®ÙØ¶"
            action_required = "Ù„Ø§ - Ø¶Ù…Ù† Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ"
        
        return {
            "Ø§Ù„ØªØ­Ù„ÙŠÙ„_Ø§Ù„Ø²Ù…Ù†ÙŠ": {
                "Ø£ÙˆÙ„_Ø­Ø¯Ø«": times[0] if times else "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ",
                "Ø¢Ø®Ø±_Ø­Ø¯Ø«": times[-1] if times else "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ",
                "Ø§Ù„ÙØªØ±Ø©_Ø§Ù„Ø²Ù…Ù†ÙŠØ©": f"{times[0]} - {times[-1]}" if times else "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ",
                "Ø¹Ø¯Ø¯_Ø§Ù„Ø£ÙˆÙ‚Ø§Øª_Ø§Ù„Ù…Ø³Ø¬Ù„Ø©": len(times)
            },
            "Ø§Ù„ØªØ­Ù„ÙŠÙ„_Ø§Ù„Ø´Ø¨ÙƒÙŠ": {
                "Ø¹Ù†Ø§ÙˆÙŠÙ†_IP_Ù…Ø®ØªÙ„ÙØ©": len(set(ips)),
                "Ø¥Ø¬Ù…Ø§Ù„ÙŠ_Ø¹Ù†Ø§ÙˆÙŠÙ†_IP": len(ips),
                "Ø¹Ù†Ø§ÙˆÙŠÙ†_URL_Ù…ÙƒØªØ´ÙØ©": len(urls)
            },
            "ØªÙ‚ÙŠÙŠÙ…_Ø§Ù„Ø®Ø·ÙˆØ±Ø©": {
                "Ù†Ù‚Ø§Ø·_Ø§Ù„Ø®Ø·ÙˆØ±Ø©_Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©": total_risk_score,
                "Ù…Ø³ØªÙˆÙ‰_Ø§Ù„Ø®Ø·ÙˆØ±Ø©_Ø§Ù„Ø´Ø§Ù…Ù„": overall_risk,
                "ÙŠØªØ·Ù„Ø¨_ØªØ¯Ø®Ù„": action_required,
                "Ø¹Ø¯Ø¯_Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯Ø§Øª_Ø§Ù„Ù…ÙƒØªØ´ÙØ©": len(suspicious_patterns)
            },
            "Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª_Ø§Ù„Ø¹Ø§Ù…Ø©": {
                "Ø¥Ø¬Ù…Ø§Ù„ÙŠ_Ø§Ù„Ø£Ø­Ø¯Ø§Ø«": len(lines),
                "Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®_Ø§Ù„Ù…Ø®ØªÙ„ÙØ©": len(set(dates)),
                "Ù…Ø¹Ø¯Ù„_Ø§Ù„Ø£Ø­Ø¯Ø§Ø«_ÙÙŠ_Ø§Ù„Ø³Ø§Ø¹Ø©": len(lines) / 24 if times else 0
            }
        }
# ==========================
# ğŸŸ¢ Ù…ÙˆÙ„Ø¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
# ==========================
class ReportGenerator:
    """Ù…ÙˆÙ„Ø¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    
    @staticmethod
    def generate_text_report(basic_analysis: Dict, suspicious_items: List[Dict], 
                             stats: Dict, analysis_time: float) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ù†ØµÙŠ Ù…ÙØµÙ„"""
        report = []
        report.append("â•”" + "â•" * 68 + "â•—")
        report.append("â•‘ ğŸ›¡  ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¬Ù†Ø§Ø¦ÙŠ Ø§Ù„Ø±Ù‚Ù…ÙŠ - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© v2.0  â•‘")
        report.append("â•š" + "â•" * 68 + "â•")
        report.append(f"ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"â±ï¸  ÙˆÙ‚Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„: {analysis_time:.2f} Ø«Ø§Ù†ÙŠØ©")
        report.append("â”€" * 70)
        report.append("ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:")
        report.append(f"   â€¢ ğŸ“„ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø·Ø±: {basic_analysis['total_lines']:,}")
        report.append(f"   â€¢ âŒ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡: {basic_analysis['errors']}")
        report.append(f"   â€¢ âš ï¸  Ø¹Ø¯Ø¯ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª: {basic_analysis['warnings']}")
        report.append(f"   â€¢ â„¹ï¸  Ø£Ø­Ø¯Ø§Ø« Ù…Ø¹Ù„ÙˆÙ…Ø§Øª: {basic_analysis['info_events']}")
        report.append("â”€" * 70)
        
        if suspicious_items:
            report.append("ğŸ” Ø§Ù„ØªÙ‡Ø¯ÙŠØ¯Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ© (Ù…ØµÙ†ÙØ© Ø­Ø³Ø¨ Ø§Ù„Ø®Ø·ÙˆØ±Ø©):")
            threats_by_level = {}
            for item in suspicious_items:
                level = item['risk_level']
                threats_by_level.setdefault(level, []).append(item)
            for level in ["Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø®Ø·ÙˆØ±Ø©", "Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·ÙˆØ±Ø©", "Ù…Ù†Ø®ÙØ¶ Ø§Ù„Ø®Ø·ÙˆØ±Ø©"]:
                if level in threats_by_level:
                    report.append(f"\n{threats_by_level[level][0]['risk_icon']} {level}:")
                    for threat in threats_by_level[level]:
                        report.append(f"   â€¢ {threat['name']} â† {threat['count']} Ù…Ø±Ø©")
                        report.append(f"     ğŸ“ {threat['description']}")
                        report.append(f"     ğŸ·  Ø§Ù„ØªØµÙ†ÙŠÙ: {threat['category']}")
                        report.append(f"     ğŸ“Š Ù†Ù‚Ø§Ø· Ø§Ù„Ø®Ø·ÙˆØ±Ø©: {threat['score']}")
                        report.append(f"     Ø£Ù…Ø«Ù„Ø©: {', '.join(threat['examples'])}")
        
        report.append("â”€" * 70)
        report.append("ğŸ“ˆ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…:")
        report.append(f"   â€¢ Ø£ÙˆÙ„ Ø­Ø¯Ø«: {stats['Ø§Ù„ØªØ­Ù„ÙŠÙ„_Ø§Ù„Ø²Ù…Ù†ÙŠ']['Ø£ÙˆÙ„_Ø­Ø¯Ø«']}")
        report.append(f"   â€¢ Ø¢Ø®Ø± Ø­Ø¯Ø«: {stats['Ø§Ù„ØªØ­Ù„ÙŠÙ„_Ø§Ù„Ø²Ù…Ù†ÙŠ']['Ø¢Ø®Ø±_Ø­Ø¯Ø«']}")
        report.append(f"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù†Ù‚Ø§Ø· Ø§Ù„Ø®Ø·ÙˆØ±Ø©: {stats['ØªÙ‚ÙŠÙŠÙ…_Ø§Ù„Ø®Ø·ÙˆØ±Ø©']['Ù†Ù‚Ø§Ø·_Ø§Ù„Ø®Ø·ÙˆØ±Ø©_Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©']}")
        report.append(f"   â€¢ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ±Ø© Ø§Ù„Ø´Ø§Ù…Ù„: {stats['ØªÙ‚ÙŠÙŠÙ…_Ø§Ù„Ø®Ø·ÙˆØ±Ø©']['Ù…Ø³ØªÙˆÙ‰_Ø§Ù„Ø®Ø·ÙˆØ±Ø©_Ø§Ù„Ø´Ø§Ù…Ù„']}")
        report.append(f"   â€¢ ÙŠØªØ·Ù„Ø¨ ØªØ¯Ø®Ù„: {stats['ØªÙ‚ÙŠÙŠÙ…_Ø§Ù„Ø®Ø·ÙˆØ±Ø©']['ÙŠØªØ·Ù„Ø¨_ØªØ¯Ø®Ù„']}")
        report.append(f"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«: {stats['Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª_Ø§Ù„Ø¹Ø§Ù…Ø©']['Ø¥Ø¬Ù…Ø§Ù„ÙŠ_Ø§Ù„Ø£Ø­Ø¯Ø§Ø«']}")
        report.append(f"   â€¢ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø®ØªÙ„ÙØ©: {stats['Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª_Ø§Ù„Ø¹Ø§Ù…Ø©']['Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®_Ø§Ù„Ù…Ø®ØªÙ„ÙØ©']}")
        report.append(f"   â€¢ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« ÙÙŠ Ø§Ù„Ø³Ø§Ø¹Ø©: {stats['Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª_Ø§Ù„Ø¹Ø§Ù…Ø©']['Ù…Ø¹Ø¯Ù„_Ø§Ù„Ø£Ø­Ø¯Ø§Ø«_ÙÙŠ_Ø§Ù„Ø³Ø§Ø¹Ø©']:.2f}")
        report.append("â”€" * 70)
        report.append("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¨Ù†Ø¬Ø§Ø­.")
        return "\n".join(report)
